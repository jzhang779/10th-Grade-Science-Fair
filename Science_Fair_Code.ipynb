{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "import os, sys, time, datetime, random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/pytorch/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "config_path='config/yolov3.cfg'\n",
    "weights_path='config/yolov3.weights'\n",
    "class_path='config/coco.names'\n",
    "img_size=416\n",
    "conf_thres=0.8\n",
    "nms_thres=0.4\n",
    "\n",
    "# Load model and weights\n",
    "model = Darknet(config_path, img_size=img_size)\n",
    "model.load_weights(weights_path)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "classes = utils.load_classes(class_path)\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     19,
     117
    ]
   },
   "outputs": [],
   "source": [
    "def detect_image(img):\n",
    "    # scale and pad image\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
    "                        (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    # convert image to Tensor\n",
    "    image_tensor = img_transforms(img).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input_img = Variable(image_tensor.type(Tensor))\n",
    "    # run inference on the model and get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_img)\n",
    "        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
    "    return detections[0]\n",
    "def get_data():\n",
    "    start_time = time.time()\n",
    "    cap = datasets.CocoCaptions(root = '/home/user/data/train2017',\n",
    "                            annFile = '/home/user/data/annotations/captions_train2017.json',\n",
    "                            transform=transforms.ToTensor())\n",
    "    print('Number of samples: ', len(cap))\n",
    "    print(\"Runtime: \", time.time() - start_time)\n",
    "    return cap\n",
    "def resize_image(image, re_type, *args, upsize = False, path = True):\n",
    "    if path:\n",
    "        img = Image.open(image)\n",
    "    else:\n",
    "        img = image\n",
    "    if re_type == 'Scale':\n",
    "        sf = args[0]\n",
    "        if not sf:\n",
    "            return img\n",
    "        width, height = img.size\n",
    "        if upsize:\n",
    "            img = img.resize((int(width / sf), int(height / sf)))\n",
    "            img = img.resize((width, height))\n",
    "        else:\n",
    "            img = img.resize((int(width / sf), int(height / sf)))\n",
    "    elif re_type == 'Percent':\n",
    "        percent_c = args[0]\n",
    "        width, height = img.size\n",
    "        if upsize:\n",
    "            img = img.resize((int(width * percent_c), int(height * percent_c)))\n",
    "            img = img.resize((width, height))\n",
    "        else:\n",
    "            img = img.resize((int(width * percent_c), int(height * percent_c)))\n",
    "    else:\n",
    "        img = img.resize(args)\n",
    "    return img\n",
    "def display_detections(list_of_imgs, resize_type, resize_arg, save = True, path = True, visualize = True):\n",
    "    x_coord = []\n",
    "    class_pred = []\n",
    "    for i in list_of_imgs:\n",
    "        count = 0\n",
    "        # load image and get detections\n",
    "        if path:\n",
    "            img_path = i\n",
    "            img = resize_image(img_path, resize_type, resize_arg, upsize = True, path = True)\n",
    "        else:\n",
    "            img = resize_image(i, resize_type, resize_arg, upsize = True, path = False)\n",
    "        prev_time = time.time()\n",
    "        detections = detect_image(img)\n",
    "        inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n",
    "        # print ('Inference Time: %s' % (inference_time))\n",
    "\n",
    "        # Get bounding-box colors\n",
    "        if visualize:\n",
    "            cmap = plt.get_cmap('tab20b')\n",
    "            colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "            img = np.array(img)\n",
    "            plt.figure()\n",
    "            fig, ax = plt.subplots(1, figsize=(8,9))\n",
    "            ax.imshow(img)\n",
    "\n",
    "            pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "            pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "            unpad_h = img_size - pad_y\n",
    "            unpad_w = img_size - pad_x\n",
    "\n",
    "        if detections is not None:\n",
    "            unique_labels = detections[:, -1].cpu().unique()\n",
    "            n_cls_preds = len(unique_labels)\n",
    "            if visualize:\n",
    "                bbox_colors = random.sample(colors, n_cls_preds)\n",
    "            # browse detections and draw bounding boxes\n",
    "            for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                if visualize:\n",
    "                    box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
    "                    box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
    "                    y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
    "                    x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
    "                    color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "                    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "                    ax.add_patch(bbox)\n",
    "                    plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top', bbox={'color': color, 'pad': 0})\n",
    "                if int(cls_pred) == 47:\n",
    "                    x_coord.append(float(conf))\n",
    "                count += 1\n",
    "                class_pred.append(cls_pred)\n",
    "        if visualize:\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        # save image\n",
    "        if save:\n",
    "            plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"), bbox_inches='tight', pad_inches=0.0)\n",
    "    return class_pred, x_coord\n",
    "def reduce_index(list_of_indexes, only_one = False):\n",
    "    res = []\n",
    "    for i in list_of_indexes:\n",
    "        print(i)\n",
    "        img, target = cap[i]\n",
    "        img_to_pil = torchvision.transforms.ToPILImage()\n",
    "        temp = img_to_pil(img)\n",
    "        class_pred, xval = display_detections([temp], 'Scale', 0, save = False, path = False, visualize = False)\n",
    "        if only_one:\n",
    "            if 47 in class_pred and class_pred.count(47) == 1:\n",
    "                res.append(i)\n",
    "        else:\n",
    "            if 47 in class_pred:\n",
    "                res.append(i)\n",
    "    return res\n",
    "def load_pickle():\n",
    "    pickle_in = open(\"coco_dataset_only_apples.pickle\", \"rb\")\n",
    "    new_indexes = pickle.load(pickle_in)\n",
    "    return new_indexes\n",
    "def display_graph(percent_chg, indexes):\n",
    "    %matplotlib inline\n",
    "    per_chg = percent_chg\n",
    "    percentshow = []\n",
    "    print(per_chg)\n",
    "    num_of_imgs = len(indexes)\n",
    "    starttime = time.time()\n",
    "    for pctc in per_chg:\n",
    "        coco_imgs = []\n",
    "        for i in range(num_of_imgs):\n",
    "            img, target = cap[indexes[i]]\n",
    "            img_to_pil = torchvision.transforms.ToPILImage()\n",
    "            temp = img_to_pil(img)\n",
    "            coco_imgs.append(temp)\n",
    "        class_predictions, x_vals = display_detections(coco_imgs, 'Percent', pctc, save = False, path = False, visualize = False)\n",
    "        percentshow.append(len(x_vals) / num_of_imgs)\n",
    "    print(percentshow)\n",
    "    print(num_of_imgs)\n",
    "    print('Runtime: ', time.time() - starttime)\n",
    "    plt.plot(per_chg, percentshow)\n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of samples:  118287\n",
      "Runtime:  0.6678028106689453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = get_data()\n",
    "new_indexes = load_pickle()\n",
    "len(new_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.98, 0.96, 0.94, 0.92, 0.9, 0.88, 0.86, 0.84, 0.82, 0.8, 0.78, 0.76, 0.74, 0.72, 0.7, 0.68, 0.66, 0.64, 0.62, 0.6, 0.58, 0.56, 0.54, 0.52, 0.5, 0.48, 0.46, 0.44, 0.42, 0.4, 0.38, 0.36, 0.34, 0.32, 0.3, 0.28, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16, 0.14, 0.12, 0.1, 0.08, 0.06, 0.04, 0.02]\n",
      "[1.0, 0.9875776397515528, 0.9813664596273292, 0.9751552795031055, 0.9813664596273292, 1.0, 0.9813664596273292, 0.9751552795031055, 0.968944099378882, 0.9751552795031055, 0.9937888198757764, 0.9813664596273292, 0.9813664596273292, 0.9875776397515528, 0.9875776397515528, 0.968944099378882, 0.9813664596273292, 0.968944099378882, 0.9751552795031055, 0.968944099378882, 0.968944099378882, 0.9565217391304348, 0.9565217391304348, 0.9627329192546584, 0.9627329192546584, 0.9440993788819876, 0.937888198757764, 0.9440993788819876, 0.9192546583850931, 0.9130434782608695, 0.906832298136646, 0.9006211180124224, 0.8881987577639752, 0.8819875776397516, 0.8944099378881988, 0.8633540372670807, 0.8633540372670807, 0.8198757763975155, 0.8074534161490683, 0.7950310559006211, 0.7701863354037267, 0.7018633540372671, 0.6770186335403726, 0.5838509316770186, 0.453416149068323, 0.34782608695652173, 0.18633540372670807, 0.08695652173913043, 0.006211180124223602, 0.0]\n",
      "161\n",
      "Runtime:  187.84783744812012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_change = (np.arange(1, 0, -0.02)).round(decimals = 2).tolist()\n",
    "display_graph(percent_change, new_indexes)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
